{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Phan Minh SÃ¡ng - 20127308</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>CÃ‚U 1</b>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) TÃ­nh há»‡ sá»‘ tÆ°Æ¡ng quan máº«u giá»¯a ğ‘Š vÃ  ğ».\n",
    "Äá»ƒ tÃ­nh há»‡ sá»‘ tÆ°Æ¡ng quan máº«u giá»¯a ğ‘Š vÃ  ğ», ta sá»­ dá»¥ng cÃ´ng thá»©c:\n",
    "\n",
    "ğ‘Ÿ = Î£((ğ‘Šáµ¢ - ğ‘ŠÌ„)(ğ»áµ¢ - ğ»Ì„)) / sqrt(Î£(ğ‘Šáµ¢ - ğ‘ŠÌ„)Â² * Î£(ğ»áµ¢ - ğ»Ì„)Â²)\n",
    "\n",
    "Trong Ä‘Ã³:\n",
    "- ğ‘Šáµ¢ vÃ  ğ»áµ¢ lÃ  giÃ¡ trá»‹ cá»§a ğ‘Š vÃ  ğ» tÆ°Æ¡ng á»©ng trong tá»«ng cáº·p hÃ¬nh chá»¯ nháº­t.\n",
    "- ğ‘ŠÌ„ vÃ  ğ»Ì„ lÃ  giÃ¡ trá»‹ trung bÃ¬nh cá»§a ğ‘Š vÃ  ğ», Ä‘Æ°á»£c tÃ­nh báº±ng cÃ¡ch láº¥y tá»•ng cÃ¡c giÃ¡ trá»‹ vÃ  chia cho sá»‘ lÆ°á»£ng hÃ¬nh chá»¯ nháº­t.\n",
    "\n",
    "Giáº£ sá»­ cÃ³ ğ‘› cáº·p hÃ¬nh chá»¯ nháº­t, ta cÃ³ thá»ƒ tÃ­nh toÃ¡n nhÆ° sau:\n",
    "\n",
    "TÃ­nh ğ‘ŠÌ„:\n",
    "ğ‘ŠÌ„ = (8.63 + 4.37 + 4.92 + 7.59 + 7.84 + 5.13 + 2.82 + 6.89 + 6.77 + 6.06 + 3.31 + 2.82 + 3.01) / 13 = 5.40\n",
    "\n",
    "TÃ­nh ğ»Ì„:\n",
    "ğ»Ì„ = (11.89 + 6.97 + 6.53 + 6.14 + 11.22 + 8.87 + 7.10 + 6.85 + 7.94 + 10.09 + 6.21 + 4.25 + 4.73) / 13 = 7.60\n",
    "\n",
    "TÃ­nh Î£((ğ‘Šáµ¢ - ğ‘ŠÌ„)(ğ»áµ¢ - ğ»Ì„)) = 41.00\n",
    "\n",
    "TÃ­nh Î£(ğ‘Šáµ¢ - ğ‘ŠÌ„)Â² = 50.47\n",
    "\n",
    "TÃ­nh Î£(ğ»áµ¢ - ğ»Ì„)Â² = 65.31\n",
    "\n",
    "Tiáº¿p theo, tÃ­nh cÄƒn báº­c hai cá»§a Î£(ğ‘Šáµ¢ - ğ‘ŠÌ„)Â² * Î£(ğ»áµ¢ - ğ»Ì„)Â²:\n",
    "\n",
    "sqrt(Î£(ğ‘Šáµ¢ - ğ‘ŠÌ„)Â² * Î£(ğ»áµ¢ - ğ»Ì„)Â²) = 57.42\n",
    "\n",
    "Cuá»‘i cÃ¹ng, tÃ­nh há»‡ sá»‘ tÆ°Æ¡ng quan máº«u ğ‘Ÿ:\n",
    "\n",
    "ğ‘Ÿ = Î£((ğ‘Šáµ¢ - ğ‘ŠÌ„)(ğ»áµ¢ - ğ»Ì„)) / sqrt(Î£(ğ‘Šáµ¢ - ğ‘ŠÌ„)Â² * Î£(ğ»áµ¢ - ğ»Ì„)Â²) â‰ˆ 0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trung bÃ¬nh cÃ¢n náº·ng:  5.396923076923078\n",
      "Trung bÃ¬nh chiá»u cao:  7.599230769230768\n",
      "Î£((ğ‘Šáµ¢ - ğ‘ŠÌ„)(ğ»áµ¢ - ğ»Ì„)):  41.00076923076924\n",
      "Î£(ğ‘Šáµ¢ - ğ‘ŠÌ„)Â²:  50.47227692307692\n",
      "Î£(ğ»áµ¢ - ğ»Ì„)Â²:  65.31449230769232\n",
      "sqrt(Î£(ğ‘Šáµ¢ - ğ‘ŠÌ„)Â² * Î£(ğ»áµ¢ - ğ»Ì„)Â²):  57.415774338103496\n",
      "Há»‡ sá»‘ tÆ°Æ¡ng quan máº«u:  0.7141028698721115\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "W = [8.63, 4.37, 4.92, 7.59, 7.84, 5.13, 2.82, 6.89, 6.77, 6.06, 3.31, 2.82, 3.01]\n",
    "H = [11.89, 6.97, 6.53, 6.14, 11.22, 8.87, 7.10, 6.85, 7.94, 10.09, 6.21, 4.25, 4.73]\n",
    "\n",
    "# TÃ­nh trung bÃ¬nh\n",
    "W_mean = sum(W) / len(W)\n",
    "H_mean = sum(H) / len(H)\n",
    "\n",
    "# TÃ­nh Î£((ğ‘Šáµ¢ - ğ‘ŠÌ„)(ğ»áµ¢ - ğ»Ì„))\n",
    "covariance_sum = 0\n",
    "for i in range(len(W)):\n",
    "    covariance_sum += (W[i] - W_mean) * (H[i] - H_mean)\n",
    "\n",
    "# TÃ­nh Î£(ğ‘Šáµ¢ - ğ‘ŠÌ„)Â² vÃ  Î£(ğ»áµ¢ - ğ»Ì„)Â²\n",
    "W_squared_sum = sum([(val - W_mean) ** 2 for val in W])\n",
    "H_squared_sum = sum([(val - H_mean) ** 2 for val in H])\n",
    "\n",
    "# TÃ­nh há»‡ sá»‘ tÆ°Æ¡ng quan máº«u\n",
    "correlation_coefficient = covariance_sum / math.sqrt(W_squared_sum * H_squared_sum)\n",
    "\n",
    "print(\"Trung bÃ¬nh cÃ¢n náº·ng: \", W_mean)\n",
    "print(\"Trung bÃ¬nh chiá»u cao: \", H_mean)\n",
    "print(\"Î£((ğ‘Šáµ¢ - ğ‘ŠÌ„)(ğ»áµ¢ - ğ»Ì„)): \", covariance_sum)\n",
    "print(\"Î£(ğ‘Šáµ¢ - ğ‘ŠÌ„)Â²: \", W_squared_sum)\n",
    "print(\"Î£(ğ»áµ¢ - ğ»Ì„)Â²: \", H_squared_sum)\n",
    "print(\"sqrt(Î£(ğ‘Šáµ¢ - ğ‘ŠÌ„)Â² * Î£(ğ»áµ¢ - ğ»Ì„)Â²): \", math.sqrt(W_squared_sum * H_squared_sum))\n",
    "print(\"Há»‡ sá»‘ tÆ°Æ¡ng quan máº«u: \", correlation_coefficient)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Kiá»ƒm Ä‘á»‹nh giáº£ thuyáº¿t â€œğ‘Š vÃ  ğ» cÃ³ tÆ°Æ¡ng quanâ€ báº±ng kiá»ƒm Ä‘á»‹nh há»‡ sá»‘ tÆ°Æ¡ng quan trong scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Há»‡ sá»‘ tÆ°Æ¡ng quan:  0.7141028698721114\n",
      "GiÃ¡ trá»‹ p:  0.006107379630926134\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "W = [8.63, 4.37, 4.92, 7.59, 7.84, 5.13, 2.82, 6.89, 6.77, 6.06, 3.31, 2.82, 3.01]\n",
    "H = [11.89, 6.97, 6.53, 6.14, 11.22, 8.87, 7.10, 6.85, 7.94, 10.09, 6.21, 4.25, 4.73]\n",
    "\n",
    "# Thá»±c hiá»‡n kiá»ƒm Ä‘á»‹nh há»‡ sá»‘ tÆ°Æ¡ng quan\n",
    "correlation, p_value = pearsonr(W, H)\n",
    "\n",
    "print(\"Há»‡ sá»‘ tÆ°Æ¡ng quan: \", correlation)\n",
    "print(\"GiÃ¡ trá»‹ p: \", p_value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta khÃ´ng cÃ³ Ä‘á»§ báº±ng chá»©ng Ä‘á»ƒ bÃ¡c bá» giáº£ thuyáº¿t khÃ´ng cÃ³ tÆ°Æ¡ng quan."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) DÃ¹ng kÄ© thuáº­t láº¥y máº«u láº¡i hoÃ¡n vá»‹, kiá»ƒm Ä‘á»‹nh giáº£ thuyáº¿t â€œğ‘Š vÃ  ğ» cÃ³ tÆ°Æ¡ng quanâ€ vÃ  so sÃ¡nh káº¿t quáº£ vá»›i CÃ¢u (b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Há»‡ sá»‘ tÆ°Æ¡ng quan thá»±c táº¿:  0.7141028698721114\n",
      "GiÃ¡ trá»‹ p:  0.0073\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "W = np.array([8.63, 4.37, 4.92, 7.59, 7.84, 5.13, 2.82, 6.89, 6.77, 6.06, 3.31, 2.82, 3.01])\n",
    "H = np.array([11.89, 6.97, 6.53, 6.14, 11.22, 8.87, 7.10, 6.85, 7.94, 10.09, 6.21, 4.25, 4.73])\n",
    "\n",
    "observed_correlation = np.corrcoef(W, H)[0, 1]  # Há»‡ sá»‘ tÆ°Æ¡ng quan thá»±c táº¿\n",
    "\n",
    "# Sá»‘ láº§n láº¥y máº«u láº¡i hoÃ¡n vá»‹\n",
    "num_permutations = 10000\n",
    "\n",
    "permutation_correlations = []\n",
    "\n",
    "for _ in range(num_permutations):\n",
    "    permuted_W = np.random.permutation(W)  # Láº¥y máº«u láº¡i hoÃ¡n vá»‹ cá»§a W\n",
    "    permuted_correlation = np.corrcoef(permuted_W, H)[0, 1]  # TÃ­nh há»‡ sá»‘ tÆ°Æ¡ng quan vá»›i máº«u hoÃ¡n vá»‹\n",
    "    permutation_correlations.append(permuted_correlation)\n",
    "\n",
    "# TÃ­nh giÃ¡ trá»‹ p\n",
    "p_value = (np.abs(permutation_correlations) >= np.abs(observed_correlation)).mean()\n",
    "\n",
    "print(\"Há»‡ sá»‘ tÆ°Æ¡ng quan thá»±c táº¿: \", observed_correlation)\n",
    "print(\"GiÃ¡ trá»‹ p: \", p_value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So sÃ¡nh\n",
    "Há»‡ sá»‘ tÆ°Æ¡ng quan thá»±c táº¿ giá»¯a 2 thuáº­t toÃ¡n Ä‘á»u giá»‘ng nhau."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>CÃ‚U 2</b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) TÃ­nh cÃ¡c giÃ¡ trá»‹ Æ°á»›c lÆ°á»£ng ğ‘‡1, ğ‘‡2, ğ‘‡3, ğ‘‡4, ğ‘‡5 cho ğœƒ tá»« máº«u dá»¯ liá»‡u Ä‘Ã£ cho.\n",
    "Äá»ƒ tÃ­nh cÃ¡c giÃ¡ trá»‹ Æ°á»›c lÆ°á»£ng ğ‘‡1, ğ‘‡2, ğ‘‡3, ğ‘‡4, ğ‘‡5 cho ğœƒ tá»« máº«u dá»¯ liá»‡u Ä‘Ã£ cho, chÃºng ta sáº½ sá»­ dá»¥ng cÃ¡c cÃ´ng thá»©c vÃ  Ä‘á»‹nh nghÄ©a Ä‘Ã£ Ä‘Æ°á»£c cung cáº¥p trong cÃ¢u há»i.\n",
    "\n",
    "Äáº§u tiÃªn, chÃºng ta cáº§n tÃ­nh trung bÃ¬nh (ğ‘‹Ì…) vÃ  Ä‘á»™ lá»‡ch chuáº©n (ğ‘†) cá»§a máº«u. Sau Ä‘Ã³, chÃºng ta sáº½ tÃ­nh trung vá»‹ (ğ‘šÌ‚) cá»§a máº«u báº±ng cÃ¡ch sáº¯p xáº¿p láº¡i cÃ¡c giÃ¡ trá»‹ tá»« bÃ© Ä‘áº¿n lá»›n vÃ  chá»n giÃ¡ trá»‹ á»Ÿ vá»‹ trÃ­ giá»¯a (náº¿u ğ‘› lÃ  sá»‘ láº») hoáº·c trung bÃ¬nh cá»§a hai giÃ¡ trá»‹ á»Ÿ hai vá»‹ trÃ­ giá»¯a (náº¿u ğ‘› lÃ  sá»‘ cháºµn).\n",
    "\n",
    "Sau Ä‘Ã¢y lÃ  cÃ¡c bÆ°á»›c chi tiáº¿t Ä‘á»ƒ tÃ­nh cÃ¡c giÃ¡ trá»‹ Æ°á»›c lÆ°á»£ng:\n",
    "\n",
    "1. TÃ­nh trung bÃ¬nh (ğ‘‹Ì…):\n",
    "\n",
    "2. TÃ­nh Ä‘á»™ lá»‡ch chuáº©n (ğ‘†):\n",
    "\n",
    "3. TÃ­nh trung vá»‹ (ğ‘šÌ‚):\n",
    "\n",
    "4. TÃ­nh cÃ¡c giÃ¡ trá»‹ Æ°á»›c lÆ°á»£ng ğ‘‡1, ğ‘‡2, ğ‘‡3, ğ‘‡4, ğ‘‡5 cho ğœƒ tá»« máº«u dá»¯ liá»‡u Ä‘Ã£ cho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 = 4.9313\n",
      "T2 = 5.7177\n",
      "T3 = 4.878878961400867\n",
      "T4 = 0.20833333333333334\n",
      "T5 = 4.7188\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Máº«u dá»¯ liá»‡u Ä‘Ã£ cho\n",
    "data = [3.1209, 3.6235, 4.4852, 0.2718, 1.6783, 4.1182, 0.7732, 1.0495, 0.2336,\n",
    "        3.4155, 0.8832, 4.2080, 0.2738, 2.7319, 2.9840, 1.1990, 4.3821, 4.3974,\n",
    "        3.0841, 1.6558, 2.8287, 2.8890, 1.4964, 3.3925]\n",
    "\n",
    "n = len(data)  # KÃ­ch thÆ°á»›c máº«u\n",
    "\n",
    "# TÃ­nh cÃ¡c giÃ¡ trá»‹ Æ°á»›c lÆ°á»£ng\n",
    "X_bar = np.mean(data)\n",
    "S = np.std(data)\n",
    "m_hat = np.median(data)\n",
    "T1 = 2 * X_bar\n",
    "T2 = 2 * m_hat\n",
    "T3 = 2 * np.sqrt(3) * S\n",
    "T4 = sum([1 if x <= 1 else 0 for x in data]) / n\n",
    "T5 = min(data) + max(data)\n",
    "\n",
    "# In káº¿t quáº£\n",
    "print(f\"T1 = {T1}\")\n",
    "print(f\"T2 = {T2}\")\n",
    "print(f\"T3 = {T3}\")\n",
    "print(f\"T4 = {T4}\")\n",
    "print(f\"T5 = {T5}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) DÃ¹ng kÄ© thuáº­t bootstrapping, so sÃ¡nh sai sá»‘ chuáº©n cá»§a cÃ¡c Æ°á»›c lÆ°á»£ng trÃªn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of T1: 0.5805153407227753\n",
      "Standard deviation of T2: 1.0836278319984958\n",
      "Standard deviation of T3: 0.437212833834691\n",
      "Standard deviation of T4: 0.0841504831801009\n",
      "Standard deviation of T5: 0.16069661190675422\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Máº«u dá»¯ liá»‡u Ä‘Ã£ cho\n",
    "data = [3.1209, 3.6235, 4.4852, 0.2718, 1.6783, 4.1182, 0.7732, 1.0495, 0.2336,\n",
    "        3.4155, 0.8832, 4.2080, 0.2738, 2.7319, 2.9840, 1.1990, 4.3821, 4.3974,\n",
    "        3.0841, 1.6558, 2.8287, 2.8890, 1.4964, 3.3925]\n",
    "\n",
    "n = len(data)  # KÃ­ch thÆ°á»›c máº«u\n",
    "num_iterations = 1000  # Sá»‘ láº§n láº·p láº¡i quÃ¡ trÃ¬nh bootstrapping\n",
    "\n",
    "T1_estimates = []  # Danh sÃ¡ch cÃ¡c Æ°á»›c lÆ°á»£ng T1\n",
    "T2_estimates = []  # Danh sÃ¡ch cÃ¡c Æ°á»›c lÆ°á»£ng T2\n",
    "T3_estimates = []  # Danh sÃ¡ch cÃ¡c Æ°á»›c lÆ°á»£ng T3\n",
    "T4_estimates = []  # Danh sÃ¡ch cÃ¡c Æ°á»›c lÆ°á»£ng T4\n",
    "T5_estimates = []  # Danh sÃ¡ch cÃ¡c Æ°á»›c lÆ°á»£ng T5\n",
    "\n",
    "# Thá»±c hiá»‡n bootstrapping\n",
    "for _ in range(num_iterations):\n",
    "    bootstrap_sample = np.random.choice(data, size=n, replace=True)  # TÃ¡i chá»n máº«u\n",
    "    \n",
    "    # TÃ­nh cÃ¡c Æ°á»›c lÆ°á»£ng trÃªn tá»« máº«u tÃ¡i chá»n\n",
    "    X_bar = np.mean(bootstrap_sample)\n",
    "    S = np.std(bootstrap_sample)\n",
    "    m_hat = np.median(bootstrap_sample)\n",
    "    T1_estimates.append(2 * X_bar)\n",
    "    T2_estimates.append(2 * m_hat)\n",
    "    T3_estimates.append(2 * np.sqrt(3) * S)\n",
    "    T4_estimates.append(sum([1 if x <= 1 else 0 for x in bootstrap_sample]) / n)\n",
    "    T5_estimates.append(min(bootstrap_sample) + max(bootstrap_sample))\n",
    "\n",
    "# TÃ­nh sai sá»‘ chuáº©n cá»§a cÃ¡c Æ°á»›c lÆ°á»£ng\n",
    "T1_std = np.std(T1_estimates)\n",
    "T2_std = np.std(T2_estimates)\n",
    "T3_std = np.std(T3_estimates)\n",
    "T4_std = np.std(T4_estimates)\n",
    "T5_std = np.std(T5_estimates)\n",
    "\n",
    "# In káº¿t quáº£\n",
    "print(f\"Standard deviation of T1: {T1_std}\")\n",
    "print(f\"Standard deviation of T2: {T2_std}\")\n",
    "print(f\"Standard deviation of T3: {T3_std}\")\n",
    "print(f\"Standard deviation of T4: {T4_std}\")\n",
    "print(f\"Standard deviation of T5: {T5_std}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Giáº£ sá»­ ta cÃ³ thÃªm thÃ´ng tin lÃ  ğœƒ Ä‘Æ°á»£c sinh tá»« phÃ¢n phá»•i chuáº©n vá»›i kÃ¬ vá»ng 5, Ä‘á»™ lá»‡ch chuáº©n 1. DÃ¹ng kÄ© thuáº­t suy diá»…n Bayes Ä‘á»ƒ Æ°á»›c lÆ°á»£ng ğœƒ. So sÃ¡nh sai sá»‘ cá»§a Æ°á»›c lÆ°á»£ng nÃ y vá»›i cÃ¡c Æ°á»›c lÆ°á»£ng trÃªn.\n",
    "Äá»ƒ sá»­ dá»¥ng ká»¹ thuáº­t suy diá»…n Bayes Ä‘á»ƒ Æ°á»›c lÆ°á»£ng ğœƒ, ta cáº§n Ã¡p dá»¥ng cÃ´ng thá»©c Bayes vÃ  sá»­ dá»¥ng phÃ¢n phá»‘i xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n.\n",
    "\n",
    "Theo Ä‘á» bÃ i, ğœƒ Ä‘Æ°á»£c sinh tá»« phÃ¢n phá»‘i chuáº©n vá»›i kÃ¬ vá»ng 5 vÃ  Ä‘á»™ lá»‡ch chuáº©n 1. Ta cÃ³ thá»ƒ sá»­ dá»¥ng phÃ¢n phá»‘i xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n Ä‘á»ƒ Æ°á»›c lÆ°á»£ng ğœƒ dá»±a trÃªn máº«u dá»¯ liá»‡u.\n",
    "\n",
    "Giáº£ sá»­ ta cÃ³ máº«u dá»¯ liá»‡u ğ‘‹1, ğ‘‹2, ..., ğ‘‹ğ‘› tá»« phÃ¢n phá»‘i ğ’°(0, ğœƒ). Vá»›i thÃ´ng tin thÃªm lÃ  ğœƒ Ä‘Æ°á»£c sinh tá»« phÃ¢n phá»‘i chuáº©n vá»›i kÃ¬ vá»ng 5 vÃ  Ä‘á»™ lá»‡ch chuáº©n 1, ta cÃ³ thá»ƒ sá»­ dá»¥ng ká»¹ thuáº­t suy diá»…n Bayes Ä‘á»ƒ tÃ­nh xÃ¡c suáº¥t cá»§a ğœƒ dá»±a trÃªn máº«u dá»¯ liá»‡u.\n",
    "\n",
    "CÃ´ng thá»©c Bayes cho xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n:\n",
    "\n",
    "ğ‘ƒ(ğœƒ|ğ‘‹1, ğ‘‹2, ..., ğ‘‹ğ‘›) = ğ‘ƒ(ğ‘‹1, ğ‘‹2, ..., ğ‘‹ğ‘›|ğœƒ) * ğ‘ƒ(ğœƒ) / ğ‘ƒ(ğ‘‹1, ğ‘‹2, ..., ğ‘‹ğ‘›)\n",
    "\n",
    "Trong Ä‘Ã³:\n",
    "- ğ‘ƒ(ğœƒ|ğ‘‹1, ğ‘‹2, ..., ğ‘‹ğ‘›) lÃ  xÃ¡c suáº¥t cá»§a ğœƒ dá»±a trÃªn máº«u dá»¯ liá»‡u.\n",
    "- ğ‘ƒ(ğ‘‹1, ğ‘‹2, ..., ğ‘‹ğ‘›|ğœƒ) lÃ  xÃ¡c suáº¥t cá»§a máº«u dá»¯ liá»‡u dá»±a trÃªn ğœƒ.\n",
    "- ğ‘ƒ(ğœƒ) lÃ  xÃ¡c suáº¥t tiá»n Ä‘á»‹nh cá»§a ğœƒ (phÃ¢n phá»‘i xÃ¡c suáº¥t cá»§a ğœƒ Ä‘Æ°á»£c sinh tá»« phÃ¢n phá»‘i chuáº©n vá»›i kÃ¬ vá»ng 5 vÃ  Ä‘á»™ lá»‡ch chuáº©n 1).\n",
    "- ğ‘ƒ(ğ‘‹1, ğ‘‹2, ..., ğ‘‹ğ‘›) lÃ  háº±ng sá»‘ chuáº©n hÃ³a.\n",
    "\n",
    "Äá»ƒ Æ°á»›c lÆ°á»£ng ğœƒ, ta cÃ³ thá»ƒ tÃ­nh xÃ¡c suáº¥t cá»§a ğœƒ dá»±a trÃªn máº«u dá»¯ liá»‡u sá»­ dá»¥ng ká»¹ thuáº­t suy diá»…n Bayes. Äiá»u nÃ y sáº½ cung cáº¥p cho ta má»™t phÃ¢n phá»‘i xÃ¡c suáº¥t cá»§a ğœƒ sau khi cÃ³ thÃ´ng tin tá»« máº«u dá»¯ liá»‡u.\n",
    "\n",
    "Äá»ƒ so sÃ¡nh sai sá»‘ cá»§a Æ°á»›c lÆ°á»£ng nÃ y vá»›i cÃ¡c Æ°á»›c lÆ°á»£ng trÆ°á»›c Ä‘Ã³, ta cÃ³ thá»ƒ tÃ­nh sai sá»‘ chuáº©n cá»§a phÃ¢n phá»‘i xÃ¡c suáº¥t cá»§a ğœƒ vÃ  so sÃ¡nh nÃ³ vá»›i sai sá»‘ chuáº©n cá»§a cÃ¡c Æ°á»›c lÆ°á»£ng trÆ°á»›c Ä‘Ã³.\n",
    "\n",
    "Tuy nhiÃªn, Ä‘á»ƒ tÃ­nh toÃ¡n cá»¥ thá»ƒ cÃ¡c giÃ¡ trá»‹ nÃ y, ta cáº§n biáº¿t cÃ¡c giÃ¡ trá»‹ cá»¥ thá»ƒ cá»§a máº«u dá»¯ liá»‡u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta estimate: 0.0001\n",
      "Standard deviation of theta estimate: 0.00024855346488431696\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Máº«u dá»¯ liá»‡u Ä‘Ã£ cho\n",
    "data = [3.1209, 3.6235, 4.4852, 0.2718, 1.6783, 4.1182, 0.7732, 1.0495, 0.2336,\n",
    "        3.4155, 0.8832, 4.2080, 0.2738, 2.7319, 2.9840, 1.1990, 4.3821, 4.3974,\n",
    "        3.0841, 1.6558, 2.8287, 2.8890, 1.4964, 3.3925]\n",
    "\n",
    "n = len(data)  # KÃ­ch thÆ°á»›c máº«u\n",
    "\n",
    "# PhÃ¢n phá»‘i xÃ¡c suáº¥t tiá»n Ä‘á»‹nh cá»§a ğœƒ (phÃ¢n phá»‘i chuáº©n)\n",
    "prior_mu = 5\n",
    "prior_sigma = 1\n",
    "\n",
    "# TÃ­nh xÃ¡c suáº¥t cá»§a ğœƒ dá»±a trÃªn máº«u dá»¯ liá»‡u sá»­ dá»¥ng suy diá»…n Bayes\n",
    "posterior_samples = norm.rvs(loc=prior_mu, scale=prior_sigma, size=10000)  # Táº¡o máº«u tá»« phÃ¢n phá»‘i xÃ¡c suáº¥t tiá»n Ä‘á»‹nh\n",
    "likelihoods = np.prod(norm.pdf(data, loc=0, scale=posterior_samples[:, np.newaxis]), axis=1)  # XÃ¡c suáº¥t cá»§a máº«u dá»¯ liá»‡u dá»±a trÃªn ğœƒ\n",
    "posteriors = prior_mu * likelihoods / np.sum(prior_mu * likelihoods)  # XÃ¡c suáº¥t cá»§a ğœƒ dá»±a trÃªn máº«u dá»¯ liá»‡u (chuáº©n hÃ³a)\n",
    "\n",
    "# TÃ­nh Æ°á»›c lÆ°á»£ng ğœƒ dá»±a trÃªn phÃ¢n phá»‘i xÃ¡c suáº¥t thu Ä‘Æ°á»£c\n",
    "theta_estimate = np.mean(posteriors)\n",
    "\n",
    "# TÃ­nh sai sá»‘ chuáº©n cá»§a Æ°á»›c lÆ°á»£ng ğœƒ\n",
    "theta_std = np.std(posteriors)\n",
    "\n",
    "# In káº¿t quáº£\n",
    "print(f\"Theta estimate: {theta_estimate}\")\n",
    "print(f\"Standard deviation of theta estimate: {theta_std}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>CÃ‚U 3</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Láº¥y bá»™ dá»¯ liá»‡u California Housing\n",
    "data = fetch_california_housing()\n",
    "X = data.data  # Äáº·c trÆ°ng\n",
    "y = data.target  # GiÃ¡ nhÃ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XÃ¡c Ä‘á»‹nh cÃ¡c mÃ´ hÃ¬nh Ä‘á»ƒ so sÃ¡nh\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    SVR(),\n",
    "    MLPRegressor()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cháº¡y kiá»ƒm tra chÃ©o vÃ  tÃ­nh toÃ¡n Ä‘iá»ƒm sá»‘ R^2\n",
    "results = []\n",
    "for model in models:\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "    results.append((model.__class__.__name__, scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: str, Mean R^2: 0.6698725554829965\n",
      "Model: str, Mean R^2: 0.6496837815751265\n",
      "Model: str, Mean R^2: 0.5530421056931838\n",
      "Model: str, Mean R^2: 0.5530311140279234\n",
      "Model: str, Mean R^2: 0.37601877846605325\n",
      "Model: str, Mean R^2: 0.2035486180756368\n",
      "Model: str, Mean R^2: -0.11011882232910505\n"
     ]
    }
   ],
   "source": [
    "# Sáº¯p xáº¿p theo thá»© tá»± giáº£m dáº§n cá»§a Ä‘iá»ƒm sá»‘ R^2\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# In káº¿t quáº£\n",
    "for name, score in results:\n",
    "    print(f\"Model: {type(name).__name__}, Mean R^2: {score.mean()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df515c7397437e016ca8f5715290d1712a5cfc8149a05970526c605fb75f36fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
